{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCA7J3emKLhkbb4gaVAGZz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abir9288/EnergyEfficientGreanAIEnvironmentMonitoringSystem/blob/main/greanAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "lNiJ9XPBnQl8",
        "outputId": "baba4f41-10f7-44a9-ad46-ad4b9512726d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-29628c09-d11b-417b-91d2-0b2812ccb44c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-29628c09-d11b-417b-91d2-0b2812ccb44c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving GlobalWeatherRepository.csv to GlobalWeatherRepository.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install codecarbon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "LoN7MhBZsGsL",
        "outputId": "1cd353e2-6635-4f98-b14c-b0f9b7644d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting codecarbon\n",
            "  Downloading codecarbon-3.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.12/dist-packages (from codecarbon) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from codecarbon) (8.3.1)\n",
            "Collecting fief-client[cli] (from codecarbon)\n",
            "  Downloading fief_client-0.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.23.1)\n",
            "Collecting psutil>=6.0.0 (from codecarbon)\n",
            "  Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.12.3)\n",
            "Collecting nvidia-ml-py (from codecarbon)\n",
            "  Downloading nvidia_ml_py-13.590.44-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting rapidfuzz (from codecarbon)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.32.4)\n",
            "Collecting questionary (from codecarbon)\n",
            "  Downloading questionary-2.1.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2025.3)\n",
            "Collecting httpx<0.28.0,>=0.21.3 (from fief-client[cli]->codecarbon)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jwcrypto<2.0.0,>=1.4 (from fief-client[cli]->codecarbon)\n",
            "  Downloading jwcrypto-1.5.6-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting yaspin (from fief-client[cli]->codecarbon)\n",
            "  Downloading yaspin-3.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->codecarbon) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.4.2)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from questionary->codecarbon) (3.0.52)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (2026.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.12/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: termcolor<4.0,>=3.2 in /usr/local/lib/python3.12/dist-packages (from yaspin->fief-client[cli]->codecarbon) (3.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.23)\n",
            "Downloading codecarbon-3.2.1-py3-none-any.whl (358 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.7/358.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-13.590.44-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading questionary-2.1.1-py3-none-any.whl (36 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jwcrypto-1.5.6-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fief_client-0.20.0-py3-none-any.whl (20 kB)\n",
            "Downloading yaspin-3.4.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: nvidia-ml-py, yaspin, rapidfuzz, psutil, questionary, httpx, jwcrypto, fief-client, codecarbon\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.55.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed codecarbon-3.2.1 fief-client-0.20.0 httpx-0.27.2 jwcrypto-1.5.6 nvidia-ml-py-13.590.44 psutil-7.2.1 questionary-2.1.1 rapidfuzz-3.14.3 yaspin-3.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "db63a630eaf34f7599e5c4ffcd9fe921"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PtS_yRoZojg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"GlobalWeatherRepository.csv\")"
      ],
      "metadata": {
        "id": "J1L8nGWKolxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[\"air_quality_us-epa-index\"])\n",
        "y = df[\"air_quality_us-epa-index\"]\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n",
        "print(\"Target classes:\\n\", y.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBalYME-on_x",
        "outputId": "02ca9a69-01c3-4fc0-a3e1-e75b6a670489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (115568, 40)\n",
            "Target shape: (115568,)\n",
            "Target classes:\n",
            " air_quality_us-epa-index\n",
            "1    60842\n",
            "2    36635\n",
            "3     9603\n",
            "4     6960\n",
            "5     1098\n",
            "6      430\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
        "numerical_cols = X.select_dtypes(include=[\"number\"]).columns\n",
        "\n",
        "print(\"Categorical columns:\")\n",
        "print(categorical_cols)\n",
        "\n",
        "print(\"\\nNumerical columns:\")\n",
        "print(numerical_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m39n7Zs4oqKx",
        "outputId": "7db94a06-8dc5-4c17-90ba-8588f65b08d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns:\n",
            "Index(['country', 'location_name', 'timezone', 'last_updated',\n",
            "       'condition_text', 'wind_direction', 'sunrise', 'sunset', 'moonrise',\n",
            "       'moonset', 'moon_phase'],\n",
            "      dtype='object')\n",
            "\n",
            "Numerical columns:\n",
            "Index(['latitude', 'longitude', 'last_updated_epoch', 'temperature_celsius',\n",
            "       'temperature_fahrenheit', 'wind_mph', 'wind_kph', 'wind_degree',\n",
            "       'pressure_mb', 'pressure_in', 'precip_mm', 'precip_in', 'humidity',\n",
            "       'cloud', 'feels_like_celsius', 'feels_like_fahrenheit', 'visibility_km',\n",
            "       'visibility_miles', 'uv_index', 'gust_mph', 'gust_kph',\n",
            "       'air_quality_Carbon_Monoxide', 'air_quality_Ozone',\n",
            "       'air_quality_Nitrogen_dioxide', 'air_quality_Sulphur_dioxide',\n",
            "       'air_quality_PM2.5', 'air_quality_PM10', 'air_quality_gb-defra-index',\n",
            "       'moon_illumination'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop(columns=[\"location_name\", \"timezone\"])"
      ],
      "metadata": {
        "id": "Wn3Kf2GQosuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution\n",
        "print(y.value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tCiqsZIouwC",
        "outputId": "7fa4a972-ac3e-4ddd-9199-6d48c862dbd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "air_quality_us-epa-index\n",
            "1    60842\n",
            "2    36635\n",
            "3     9603\n",
            "4     6960\n",
            "5     1098\n",
            "6      430\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "    X[col] = le.fit_transform(X[col])"
      ],
      "metadata": {
        "id": "wzf0GUfQoyEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.select_dtypes(include=[\"object\"]).columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6m1nfCco2HZ",
        "outputId": "2560e84d-cbae-42a7-84c9-2c9c4948bd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[\"air_quality_us-epa-index\"])\n",
        "y = df[\"air_quality_us-epa-index\"]"
      ],
      "metadata": {
        "id": "kf7fIBPeo4Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollutant_cols = [\n",
        "    \"air_quality_PM2.5\",\n",
        "    \"air_quality_PM10\",\n",
        "    \"air_quality_Ozone\",\n",
        "    \"air_quality_Carbon_Monoxide\",\n",
        "    \"air_quality_Nitrogen_dioxide\",\n",
        "    \"air_quality_Sulphur_dioxide\"\n",
        "]\n",
        "\n",
        "X = X.drop(columns=pollutant_cols)"
      ],
      "metadata": {
        "id": "LNa-6pyOo6xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([c for c in X.columns if \"air_quality\" in c])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHN1W0NEo846",
        "outputId": "855d975b-52a4-40cf-8791-13d73d467676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['air_quality_gb-defra-index']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.select_dtypes(include=[\"int64\", \"float64\"])"
      ],
      "metadata": {
        "id": "_V4fMO1ao_L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LR"
      ],
      "metadata": {
        "id": "HnHAlaUJpMPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",\n",
        "        solver=\"lbfgs\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Training with time measurement\n",
        "start_time = time.time()\n",
        "pipeline.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "macro_precision = precision_score(y_test, y_pred, average=\"macro\") * 100\n",
        "macro_recall = recall_score(y_test, y_pred, average=\"macro\") * 100\n",
        "macro_f1 = f1_score(y_test, y_pred, average=\"macro\") * 100\n",
        "class_labels = np.unique(y)\n",
        "\n",
        "# Print Results\n",
        "print(\"--------- Dataset Info ---------\")\n",
        "print(\"Total samples:\", len(X))\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Class labels:\", class_labels)\n",
        "\n",
        "print(\"\\n--------- Training Info ---------\")\n",
        "print(\"Training time (seconds):\", round(training_time, 4))\n",
        "print(\"Max iterations (epochs):\", 1000)\n",
        "print(\"Optimizer:\", \"lbfgs\")\n",
        "print(\"Batch size: N/A (full batch)\")\n",
        "print(\"Learning rate: N/A (solver controls internally)\")\n",
        "\n",
        "print(\"\\n--------- Performance Metrics ---------\")\n",
        "print(\"Accuracy (%):\", round(accuracy, 2))\n",
        "print(\"Macro Precision (%):\", round(macro_precision, 2))\n",
        "print(\"Macro Recall (%):\", round(macro_recall, 2))\n",
        "print(\"Macro F1-score (%):\", round(macro_f1, 2))\n",
        "\n",
        "print(\"\\n--------- Detailed Classification Report ---------\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKk9RzTBpNqi",
        "outputId": "d1fec383-9201-48eb-e8b8-1d463c792b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Dataset Info ---------\n",
            "Total samples: 115568\n",
            "Training samples: 92454\n",
            "Testing samples: 23114\n",
            "Class labels: [1 2 3 4 5 6]\n",
            "\n",
            "--------- Training Info ---------\n",
            "Training time (seconds): 34.4462\n",
            "Max iterations (epochs): 1000\n",
            "Optimizer: lbfgs\n",
            "Batch size: N/A (full batch)\n",
            "Learning rate: N/A (solver controls internally)\n",
            "\n",
            "--------- Performance Metrics ---------\n",
            "Accuracy (%): 84.01\n",
            "Macro Precision (%): 64.16\n",
            "Macro Recall (%): 74.53\n",
            "Macro F1-score (%): 64.2\n",
            "\n",
            "--------- Detailed Classification Report ---------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89     12169\n",
            "           2       0.74      0.94      0.82      7327\n",
            "           3       0.80      0.97      0.88      1921\n",
            "           4       0.93      0.54      0.68      1392\n",
            "           5       0.24      0.58      0.34       219\n",
            "           6       0.15      0.65      0.24        86\n",
            "\n",
            "    accuracy                           0.84     23114\n",
            "   macro avg       0.64      0.75      0.64     23114\n",
            "weighted avg       0.88      0.84      0.85     23114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Random Forest"
      ],
      "metadata": {
        "id": "s2AhfExnqv8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------------\n",
        "# Train-test split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Random Forest model\n",
        "# -----------------------------\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Training with time measurement\n",
        "# -----------------------------\n",
        "start_time = time.time()\n",
        "rf_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# -----------------------------\n",
        "# Predictions\n",
        "# -----------------------------\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation Metrics\n",
        "# -----------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred_rf) * 100\n",
        "macro_precision = precision_score(y_test, y_pred_rf, average=\"macro\") * 100\n",
        "macro_recall = recall_score(y_test, y_pred_rf, average=\"macro\") * 100\n",
        "macro_f1 = f1_score(y_test, y_pred_rf, average=\"macro\") * 100\n",
        "class_labels = np.unique(y)\n",
        "\n",
        "# -----------------------------\n",
        "# Print Results\n",
        "# -----------------------------\n",
        "print(\"--------- Dataset Info ---------\")\n",
        "print(\"Total samples:\", len(X))\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Class labels:\", class_labels)\n",
        "\n",
        "print(\"\\n--------- Training Info ---------\")\n",
        "print(\"Training time (seconds):\", round(training_time, 4))\n",
        "print(\"Number of trees (n_estimators):\", 100)\n",
        "print(\"Optimizer: N/A (Random Forest uses ensemble of decision trees)\")\n",
        "print(\"Batch size: N/A (tree-based models use full data)\")\n",
        "print(\"Learning rate: N/A\")\n",
        "\n",
        "print(\"\\n--------- Performance Metrics ---------\")\n",
        "print(\"Accuracy (%):\", round(accuracy, 2))\n",
        "print(\"Macro Precision (%):\", round(macro_precision, 2))\n",
        "print(\"Macro Recall (%):\", round(macro_recall, 2))\n",
        "print(\"Macro F1-score (%):\", round(macro_f1, 2))\n",
        "\n",
        "print(\"\\n--------- Detailed Classification Report ---------\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "from codecarbon import EmissionsTracker\n",
        "import time\n",
        "\n",
        "# Start tracker\n",
        "tracker_rf = EmissionsTracker(project_name=\"Random_Forest_AQI\")\n",
        "start_time = time.time()\n",
        "\n",
        "tracker_rf.start()\n",
        "\n",
        "# Train model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Stop tracker\n",
        "emissions_rf = tracker_rf.stop()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Random Forest Training Time (s):\", end_time - start_time)\n",
        "print(\"Random Forest CO2 Emissions (kg):\", emissions_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHZDkTsNq7-6",
        "outputId": "0e8682aa-6272-44ec-c5d1-7da127d1503b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Dataset Info ---------\n",
            "Total samples: 115568\n",
            "Training samples: 92454\n",
            "Testing samples: 23114\n",
            "Class labels: [1 2 3 4 5 6]\n",
            "\n",
            "--------- Training Info ---------\n",
            "Training time (seconds): 15.478\n",
            "Number of trees (n_estimators): 100\n",
            "Optimizer: N/A (Random Forest uses ensemble of decision trees)\n",
            "Batch size: N/A (tree-based models use full data)\n",
            "Learning rate: N/A\n",
            "\n",
            "--------- Performance Metrics ---------\n",
            "Accuracy (%): 88.79\n",
            "Macro Precision (%): 78.76\n",
            "Macro Recall (%): 71.21\n",
            "Macro F1-score (%): 73.28\n",
            "\n",
            "--------- Detailed Classification Report ---------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.88      0.91     12169\n",
            "           2       0.80      0.91      0.85      7327\n",
            "           3       0.98      0.90      0.94      1921\n",
            "           4       0.87      0.98      0.92      1392\n",
            "           5       0.48      0.18      0.26       219\n",
            "           6       0.65      0.43      0.52        86\n",
            "\n",
            "    accuracy                           0.89     23114\n",
            "   macro avg       0.79      0.71      0.73     23114\n",
            "weighted avg       0.89      0.89      0.89     23114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 06:05:34] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 06:05:34] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 06:05:34] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 06:05:36] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 06:05:36] CPU Model on constant consumption mode: AMD EPYC 7B12\n",
            "[codecarbon WARNING @ 06:05:36] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 06:05:36] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 06:05:36] No GPU found.\n",
            "[codecarbon INFO @ 06:05:36] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 06:05:36] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 06:05:36]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 06:05:36]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 06:05:36]   CodeCarbon version: 3.2.1\n",
            "[codecarbon INFO @ 06:05:36]   Available RAM : 12.671 GB\n",
            "[codecarbon INFO @ 06:05:36]   CPU count: 2 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 06:05:36]   CPU model: AMD EPYC 7B12\n",
            "[codecarbon INFO @ 06:05:36]   GPU count: None\n",
            "[codecarbon INFO @ 06:05:36]   GPU model: None\n",
            "[codecarbon INFO @ 06:05:36] Emissions data (if any) will be saved to file /content/emissions.csv\n",
            "[codecarbon INFO @ 06:05:51] Energy consumed for RAM : 0.000041 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 06:05:51] Delta energy consumed for CPU with constant : 0.000490 kWh, power : 120.0 W\n",
            "[codecarbon INFO @ 06:05:51] Energy consumed for All CPU : 0.000490 kWh\n",
            "[codecarbon INFO @ 06:05:51] 0.000531 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Training Time (s): 14.721669912338257\n",
            "Random Forest CO2 Emissions (kg): 0.0003411637993864767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimized Random Forest"
      ],
      "metadata": {
        "id": "aNQ6T3lctEcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from codecarbon import EmissionsTracker\n",
        "\n",
        "# -----------------------------\n",
        "# Train-test split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Optimized Random Forest model\n",
        "# -----------------------------\n",
        "rf_optimized = RandomForestClassifier(\n",
        "    n_estimators=50,          # ↓ fewer trees (energy efficient)\n",
        "    max_depth=12,             # ↓ shallower trees\n",
        "    max_features=\"sqrt\",      # ↓ fewer features per split\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Training with CO2 tracking\n",
        "# -----------------------------\n",
        "train_tracker = EmissionsTracker(\n",
        "    project_name=\"RF_Optimized_Training\",\n",
        "    output_dir=\".\",\n",
        "    log_level=\"error\"\n",
        ")\n",
        "\n",
        "train_tracker.start()\n",
        "train_start = time.time()\n",
        "\n",
        "rf_optimized.fit(X_train, y_train)\n",
        "\n",
        "train_end = time.time()\n",
        "training_time = train_end - train_start\n",
        "training_emissions = train_tracker.stop()\n",
        "\n",
        "# -----------------------------\n",
        "# Inference with CO2 tracking\n",
        "# -----------------------------\n",
        "infer_tracker = EmissionsTracker(\n",
        "    project_name=\"RF_Optimized_Inference\",\n",
        "    output_dir=\".\",\n",
        "    log_level=\"error\"\n",
        ")\n",
        "\n",
        "infer_tracker.start()\n",
        "infer_start = time.time()\n",
        "\n",
        "y_pred_rf = rf_optimized.predict(X_test)\n",
        "\n",
        "infer_end = time.time()\n",
        "inference_time = infer_end - infer_start\n",
        "inference_emissions = infer_tracker.stop()\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation Metrics\n",
        "# -----------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred_rf) * 100\n",
        "macro_precision = precision_score(y_test, y_pred_rf, average=\"macro\") * 100\n",
        "macro_recall = recall_score(y_test, y_pred_rf, average=\"macro\") * 100\n",
        "macro_f1 = f1_score(y_test, y_pred_rf, average=\"macro\") * 100\n",
        "class_labels = np.unique(y)\n",
        "\n",
        "# -----------------------------\n",
        "# Print Results\n",
        "# -----------------------------\n",
        "print(\"========= Optimized Random Forest =========\")\n",
        "\n",
        "print(\"\\n--------- Dataset Info ---------\")\n",
        "print(\"Total samples:\", len(X))\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Class labels:\", class_labels)\n",
        "\n",
        "print(\"\\n--------- Model Configuration ---------\")\n",
        "print(\"Number of trees:\", 50)\n",
        "print(\"Max depth:\", 12)\n",
        "print(\"Max features:\", \"sqrt\")\n",
        "print(\"Class weighting:\", \"balanced\")\n",
        "\n",
        "print(\"\\n--------- Training Info ---------\")\n",
        "print(\"Training time (seconds):\", round(training_time, 4))\n",
        "print(\"Training CO2 emissions (kg):\", round(training_emissions, 6))\n",
        "\n",
        "print(\"\\n--------- Inference Info ---------\")\n",
        "print(\"Inference time (seconds):\", round(inference_time, 4))\n",
        "print(\"Inference CO2 emissions (kg):\", round(inference_emissions, 6))\n",
        "\n",
        "print(\"\\n--------- Performance Metrics ---------\")\n",
        "print(\"Accuracy (%):\", round(accuracy, 2))\n",
        "print(\"Macro Precision (%):\", round(macro_precision, 2))\n",
        "print(\"Macro Recall (%):\", round(macro_recall, 2))\n",
        "print(\"Macro F1-score (%):\", round(macro_f1, 2))\n",
        "\n",
        "print(\"\\n--------- Detailed Classification Report ---------\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXhHa8axtDwc",
        "outputId": "7f45fba4-bf80-4904-b362-5a6230227cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 06:06:39] Multiple instances of codecarbon are allowed to run at the same time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Optimized Random Forest =========\n",
            "\n",
            "--------- Dataset Info ---------\n",
            "Total samples: 115568\n",
            "Training samples: 92454\n",
            "Testing samples: 23114\n",
            "Class labels: [1 2 3 4 5 6]\n",
            "\n",
            "--------- Model Configuration ---------\n",
            "Number of trees: 50\n",
            "Max depth: 12\n",
            "Max features: sqrt\n",
            "Class weighting: balanced\n",
            "\n",
            "--------- Training Info ---------\n",
            "Training time (seconds): 7.0766\n",
            "Training CO2 emissions (kg): 1e-06\n",
            "\n",
            "--------- Inference Info ---------\n",
            "Inference time (seconds): 0.1746\n",
            "Inference CO2 emissions (kg): 0.0\n",
            "\n",
            "--------- Performance Metrics ---------\n",
            "Accuracy (%): 86.49\n",
            "Macro Precision (%): 73.87\n",
            "Macro Recall (%): 77.44\n",
            "Macro F1-score (%): 75.23\n",
            "\n",
            "--------- Detailed Classification Report ---------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.82      0.90     12169\n",
            "           2       0.75      0.92      0.83      7327\n",
            "           3       0.80      0.97      0.88      1921\n",
            "           4       0.91      0.91      0.91      1392\n",
            "           5       0.43      0.44      0.43       219\n",
            "           6       0.56      0.58      0.57        86\n",
            "\n",
            "    accuracy                           0.86     23114\n",
            "   macro avg       0.74      0.77      0.75     23114\n",
            "weighted avg       0.89      0.86      0.87     23114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree model"
      ],
      "metadata": {
        "id": "7hD4yoddtaAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------------\n",
        "# Train-test split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Decision Tree model\n",
        "# -----------------------------\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    max_depth=10,          # prevents overfitting\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Training with time measurement\n",
        "# -----------------------------\n",
        "start_time = time.time()\n",
        "dt_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# -----------------------------\n",
        "# Predictions\n",
        "# -----------------------------\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation Metrics\n",
        "# -----------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred_dt) * 100\n",
        "macro_precision = precision_score(y_test, y_pred_dt, average=\"macro\") * 100\n",
        "macro_recall = recall_score(y_test, y_pred_dt, average=\"macro\") * 100\n",
        "macro_f1 = f1_score(y_test, y_pred_dt, average=\"macro\") * 100\n",
        "class_labels = np.unique(y)\n",
        "\n",
        "# -----------------------------\n",
        "# Print Results\n",
        "# -----------------------------\n",
        "print(\"--------- Dataset Info ---------\")\n",
        "print(\"Total samples:\", len(X))\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Class labels:\", class_labels)\n",
        "\n",
        "print(\"\\n--------- Training Info ---------\")\n",
        "print(\"Training time (seconds):\", round(training_time, 4))\n",
        "print(\"Max depth:\", 10)\n",
        "print(\"Optimizer: N/A (Decision Tree uses greedy splitting)\")\n",
        "print(\"Batch size: N/A (tree-based model uses full data)\")\n",
        "print(\"Learning rate: N/A\")\n",
        "\n",
        "print(\"\\n--------- Performance Metrics ---------\")\n",
        "print(\"Accuracy (%):\", round(accuracy, 2))\n",
        "print(\"Macro Precision (%):\", round(macro_precision, 2))\n",
        "print(\"Macro Recall (%):\", round(macro_recall, 2))\n",
        "print(\"Macro F1-score (%):\", round(macro_f1, 2))\n",
        "\n",
        "print(\"\\n--------- Detailed Classification Report ---------\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "\n",
        "tracker_dt = EmissionsTracker(project_name=\"Decision_Tree_AQI\")\n",
        "\n",
        "start_time = time.time()\n",
        "tracker_dt.start()\n",
        "\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "emissions_dt = tracker_dt.stop()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Decision Tree Training Time (s):\", round(end_time - start_time, 4))\n",
        "print(\"Decision Tree CO2 Emissions (kg):\", emissions_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEPd_dw2t5iT",
        "outputId": "e57015f1-5f66-4e3a-e224-3da941ae813d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:05:56] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:05:56] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:05:56] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 10:05:56] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 10:05:56] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 10:05:56] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 10:05:56] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:05:57] No GPU found.\n",
            "[codecarbon INFO @ 10:05:57] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 10:05:57] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:05:57]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 10:05:57]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 10:05:57]   CodeCarbon version: 3.2.1\n",
            "[codecarbon INFO @ 10:05:57]   Available RAM : 12.671 GB\n",
            "[codecarbon INFO @ 10:05:57]   CPU count: 2 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 10:05:57]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 10:05:57]   GPU count: None\n",
            "[codecarbon INFO @ 10:05:57]   GPU model: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Dataset Info ---------\n",
            "Total samples: 115568\n",
            "Training samples: 92454\n",
            "Testing samples: 23114\n",
            "Class labels: [1 2 3 4 5 6]\n",
            "\n",
            "--------- Training Info ---------\n",
            "Training time (seconds): 2.3088\n",
            "Max depth: 10\n",
            "Optimizer: N/A (Decision Tree uses greedy splitting)\n",
            "Batch size: N/A (tree-based model uses full data)\n",
            "Learning rate: N/A\n",
            "\n",
            "--------- Performance Metrics ---------\n",
            "Accuracy (%): 85.65\n",
            "Macro Precision (%): 67.37\n",
            "Macro Recall (%): 78.41\n",
            "Macro F1-score (%): 69.76\n",
            "\n",
            "--------- Detailed Classification Report ---------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.82      0.90     12169\n",
            "           2       0.75      0.93      0.83      7327\n",
            "           3       0.81      0.97      0.88      1921\n",
            "           4       0.94      0.72      0.82      1392\n",
            "           5       0.27      0.48      0.34       219\n",
            "           6       0.28      0.79      0.42        86\n",
            "\n",
            "    accuracy                           0.86     23114\n",
            "   macro avg       0.67      0.78      0.70     23114\n",
            "weighted avg       0.89      0.86      0.86     23114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:05:57] Emissions data (if any) will be saved to file /content/emissions.csv\n",
            "[codecarbon INFO @ 10:06:01] Energy consumed for RAM : 0.000013 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:06:01] Delta energy consumed for CPU with constant : 0.000055 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:06:01] Energy consumed for All CPU : 0.000055 kWh\n",
            "[codecarbon INFO @ 10:06:01] 0.000068 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Training Time (s): 4.6762\n",
            "Decision Tree CO2 Emissions (kg): 1.8090387380506963e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIMIZED DECISION TREE"
      ],
      "metadata": {
        "id": "CpueeDqQuBUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from codecarbon import EmissionsTracker\n",
        "\n",
        "# -----------------------------\n",
        "# Train-test split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Optimized Decision Tree\n",
        "# -----------------------------\n",
        "dt_optimized = DecisionTreeClassifier(\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=5,\n",
        "    ccp_alpha=0.001,         # pruning parameter\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Training with CO2 tracking\n",
        "# -----------------------------\n",
        "train_tracker = EmissionsTracker(\n",
        "    project_name=\"DT_Optimized_Training\",\n",
        "    output_dir=\".\",\n",
        "    log_level=\"error\"\n",
        ")\n",
        "\n",
        "train_tracker.start()\n",
        "train_start = time.time()\n",
        "\n",
        "dt_optimized.fit(X_train, y_train)\n",
        "\n",
        "train_end = time.time()\n",
        "training_time = train_end - train_start\n",
        "training_emissions = train_tracker.stop()\n",
        "\n",
        "# -----------------------------\n",
        "# Inference with CO2 tracking\n",
        "# -----------------------------\n",
        "infer_tracker = EmissionsTracker(\n",
        "    project_name=\"DT_Optimized_Inference\",\n",
        "    output_dir=\".\",\n",
        "    log_level=\"error\"\n",
        ")\n",
        "\n",
        "infer_tracker.start()\n",
        "infer_start = time.time()\n",
        "\n",
        "y_pred_dt = dt_optimized.predict(X_test)\n",
        "\n",
        "infer_end = time.time()\n",
        "inference_time = infer_end - infer_start\n",
        "inference_emissions = infer_tracker.stop()\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation Metrics\n",
        "# -----------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred_dt) * 100\n",
        "macro_precision = precision_score(y_test, y_pred_dt, average=\"macro\") * 100\n",
        "macro_recall = recall_score(y_test, y_pred_dt, average=\"macro\") * 100\n",
        "macro_f1 = f1_score(y_test, y_pred_dt, average=\"macro\") * 100\n",
        "class_labels = np.unique(y)\n",
        "\n",
        "# -----------------------------\n",
        "# Print Results\n",
        "# -----------------------------\n",
        "print(\"========= Optimized Decision Tree =========\")\n",
        "\n",
        "print(\"\\n--------- Dataset Info ---------\")\n",
        "print(\"Total samples:\", len(X))\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Class labels:\", class_labels)\n",
        "\n",
        "print(\"\\n--------- Model Configuration ---------\")\n",
        "print(\"Max depth:\", 10)\n",
        "print(\"Min samples per leaf:\", 5)\n",
        "print(\"Cost complexity pruning (ccp_alpha): 0.001\")\n",
        "\n",
        "print(\"\\n--------- Training Info ---------\")\n",
        "print(\"Training time (seconds):\", round(training_time, 4))\n",
        "print(\"Training CO2 emissions (kg):\", round(training_emissions, 6))\n",
        "\n",
        "print(\"\\n--------- Inference Info ---------\")\n",
        "print(\"Inference time (seconds):\", round(inference_time, 4))\n",
        "print(\"Inference CO2 emissions (kg):\", round(inference_emissions, 6))\n",
        "\n",
        "print(\"\\n--------- Performance Metrics ---------\")\n",
        "print(\"Accuracy (%):\", round(accuracy, 2))\n",
        "print(\"Macro Precision (%):\", round(macro_precision, 2))\n",
        "print(\"Macro Recall (%):\", round(macro_recall, 2))\n",
        "print(\"Macro F1-score (%):\", round(macro_f1, 2))\n",
        "\n",
        "print(\"\\n--------- Detailed Classification Report ---------\")\n",
        "print(classification_report(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhQwSRELuD-z",
        "outputId": "975edc6c-7c97-4ed7-e20a-c1c8b7b86cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 10:06:32] Multiple instances of codecarbon are allowed to run at the same time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Optimized Decision Tree =========\n",
            "\n",
            "--------- Dataset Info ---------\n",
            "Total samples: 115568\n",
            "Training samples: 92454\n",
            "Testing samples: 23114\n",
            "Class labels: [1 2 3 4 5 6]\n",
            "\n",
            "--------- Model Configuration ---------\n",
            "Max depth: 10\n",
            "Min samples per leaf: 5\n",
            "Cost complexity pruning (ccp_alpha): 0.001\n",
            "\n",
            "--------- Training Info ---------\n",
            "Training time (seconds): 0.735\n",
            "Training CO2 emissions (kg): 3e-06\n",
            "\n",
            "--------- Inference Info ---------\n",
            "Inference time (seconds): 0.0085\n",
            "Inference CO2 emissions (kg): 0.0\n",
            "\n",
            "--------- Performance Metrics ---------\n",
            "Accuracy (%): 84.11\n",
            "Macro Precision (%): 65.4\n",
            "Macro Recall (%): 77.83\n",
            "Macro F1-score (%): 66.86\n",
            "\n",
            "--------- Detailed Classification Report ---------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89     12169\n",
            "           2       0.74      0.92      0.82      7327\n",
            "           3       0.76      0.99      0.86      1921\n",
            "           4       0.95      0.61      0.74      1392\n",
            "           5       0.22      0.54      0.31       219\n",
            "           6       0.26      0.80      0.39        86\n",
            "\n",
            "    accuracy                           0.84     23114\n",
            "   macro avg       0.65      0.78      0.67     23114\n",
            "weighted avg       0.88      0.84      0.85     23114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting"
      ],
      "metadata": {
        "id": "m-SB7F_ju3QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------------\n",
        "# Train-test split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Gradient Boosting model\n",
        "# -----------------------------\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Training with time measurement\n",
        "# -----------------------------\n",
        "start_time = time.time()\n",
        "gb_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# -----------------------------\n",
        "# Predictions\n",
        "# -----------------------------\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation Metrics\n",
        "# -----------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred_gb) * 100\n",
        "macro_precision = precision_score(y_test, y_pred_gb, average=\"macro\") * 100\n",
        "macro_recall = recall_score(y_test, y_pred_gb, average=\"macro\") * 100\n",
        "macro_f1 = f1_score(y_test, y_pred_gb, average=\"macro\") * 100\n",
        "class_labels = np.unique(y)\n",
        "\n",
        "# -----------------------------\n",
        "# Print Results\n",
        "# -----------------------------\n",
        "print(\"--------- Dataset Info ---------\")\n",
        "print(\"Total samples:\", len(X))\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Class labels:\", class_labels)\n",
        "\n",
        "print(\"\\n--------- Training Info ---------\")\n",
        "print(\"Training time (seconds):\", round(training_time, 4))\n",
        "print(\"Number of estimators (n_estimators):\", 100)\n",
        "print(\"Learning rate:\", 0.1)\n",
        "print(\"Max depth:\", 3)\n",
        "print(\"Optimizer: N/A (Gradient Boosting uses stage-wise additive trees)\")\n",
        "print(\"Batch size: N/A (tree-based model uses full data)\")\n",
        "\n",
        "print(\"\\n--------- Performance Metrics ---------\")\n",
        "print(\"Accuracy (%):\", round(accuracy, 2))\n",
        "print(\"Macro Precision (%):\", round(macro_precision, 2))\n",
        "print(\"Macro Recall (%):\", round(macro_recall, 2))\n",
        "print(\"Macro F1-score (%):\", round(macro_f1, 2))\n",
        "\n",
        "print(\"\\n--------- Detailed Classification Report ---------\")\n",
        "print(classification_report(y_test, y_pred_gb))\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "tracker_gb = EmissionsTracker(project_name=\"Gradient_Boosting_AQI\")\n",
        "\n",
        "start_time = time.time()\n",
        "tracker_gb.start()\n",
        "\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "emissions_gb = tracker_gb.stop()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Gradient Boosting Training Time (s):\", round(end_time - start_time, 4))\n",
        "print(\"Gradient Boosting CO2 Emissions (kg):\", emissions_gb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfp1Eb0zu6WT",
        "outputId": "9abf90d5-8958-4c4c-ff95-d2c30e107e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:14:26] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:14:26] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:14:26] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 10:14:26] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 10:14:26] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 10:14:26] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 10:14:26] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:14:26] No GPU found.\n",
            "[codecarbon INFO @ 10:14:26] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 10:14:26] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:14:26]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 10:14:26]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 10:14:26]   CodeCarbon version: 3.2.1\n",
            "[codecarbon INFO @ 10:14:26]   Available RAM : 12.671 GB\n",
            "[codecarbon INFO @ 10:14:26]   CPU count: 2 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 10:14:26]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 10:14:26]   GPU count: None\n",
            "[codecarbon INFO @ 10:14:26]   GPU model: None\n",
            "[codecarbon INFO @ 10:14:26] Emissions data (if any) will be saved to file /content/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Dataset Info ---------\n",
            "Total samples: 115568\n",
            "Training samples: 92454\n",
            "Testing samples: 23114\n",
            "Class labels: [1 2 3 4 5 6]\n",
            "\n",
            "--------- Training Info ---------\n",
            "Training time (seconds): 231.9068\n",
            "Number of estimators (n_estimators): 100\n",
            "Learning rate: 0.1\n",
            "Max depth: 3\n",
            "Optimizer: N/A (Gradient Boosting uses stage-wise additive trees)\n",
            "Batch size: N/A (tree-based model uses full data)\n",
            "\n",
            "--------- Performance Metrics ---------\n",
            "Accuracy (%): 87.84\n",
            "Macro Precision (%): 72.84\n",
            "Macro Recall (%): 67.01\n",
            "Macro F1-score (%): 67.77\n",
            "\n",
            "--------- Detailed Classification Report ---------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.83      0.90     12169\n",
            "           2       0.76      0.97      0.85      7327\n",
            "           3       1.00      0.89      0.94      1921\n",
            "           4       0.84      0.96      0.90      1392\n",
            "           5       0.46      0.12      0.19       219\n",
            "           6       0.34      0.26      0.29        86\n",
            "\n",
            "    accuracy                           0.88     23114\n",
            "   macro avg       0.73      0.67      0.68     23114\n",
            "weighted avg       0.89      0.88      0.88     23114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:14:41] Energy consumed for RAM : 0.000042 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:14:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:14:41] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 10:14:41] 0.000219 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:14:56] Energy consumed for RAM : 0.000083 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:14:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:14:56] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 10:14:56] 0.000437 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:15:11] Energy consumed for RAM : 0.000125 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:15:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:15:11] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 10:15:11] 0.000656 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:15:26] Energy consumed for RAM : 0.000167 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:15:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:15:26] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 10:15:26] 0.000875 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:15:41] Energy consumed for RAM : 0.000208 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:15:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:15:41] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 10:15:41] 0.001093 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:15:56] Energy consumed for RAM : 0.000250 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:15:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:15:56] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 10:15:56] 0.001312 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:16:11] Energy consumed for RAM : 0.000292 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:16:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:16:11] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 10:16:11] 0.001531 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:16:26] Energy consumed for RAM : 0.000333 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:16:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:16:26] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 10:16:26] 0.001749 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:16:26] 0.003901 g.CO2eq/s mean an estimation of 123.01584082045002 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:16:41] Energy consumed for RAM : 0.000375 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:16:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:16:41] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 10:16:41] 0.001968 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:16:56] Energy consumed for RAM : 0.000416 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:16:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:16:56] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 10:16:56] 0.002187 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:17:11] Energy consumed for RAM : 0.000458 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:17:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:17:11] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 10:17:11] 0.002405 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:17:26] Energy consumed for RAM : 0.000500 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:17:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:17:26] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 10:17:26] 0.002624 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:17:41] Energy consumed for RAM : 0.000541 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:17:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:17:41] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 10:17:41] 0.002843 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:17:56] Energy consumed for RAM : 0.000583 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:17:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:17:56] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 10:17:56] 0.003061 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:18:11] Energy consumed for RAM : 0.000625 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:18:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:18:11] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 10:18:11] 0.003280 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:18:14] Energy consumed for RAM : 0.000632 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:18:14] Delta energy consumed for CPU with constant : 0.000030 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:18:14] Energy consumed for All CPU : 0.002685 kWh\n",
            "[codecarbon INFO @ 10:18:14] 0.003317 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:18:14] 0.003901 g.CO2eq/s mean an estimation of 123.01681295265281 kg.CO2eq/year\n",
            "[codecarbon WARNING @ 10:18:14] The CSV format has changed, backing up old emission file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Training Time (s): 227.5845\n",
            "Gradient Boosting CO2 Emissions (kg): 0.0008877257471837294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimized Gradient Boosting"
      ],
      "metadata": {
        "id": "9CxhrEqCvDU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from codecarbon import EmissionsTracker\n",
        "\n",
        "# -----------------------------\n",
        "# Train-test split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Gradient Boosting model\n",
        "# -----------------------------\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=200,       # more trees for stability\n",
        "    learning_rate=0.05,     # lower to reduce overfitting\n",
        "    max_depth=5,            # shallow trees = faster + efficient\n",
        "    min_samples_leaf=5,\n",
        "    subsample=0.8,          # stochastic gradient boosting\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Energy tracking\n",
        "# -----------------------------\n",
        "tracker = EmissionsTracker(project_name=\"Optimized_GB\")\n",
        "tracker.start()\n",
        "\n",
        "# -----------------------------\n",
        "# Training with time measurement\n",
        "# -----------------------------\n",
        "start_time = time.time()\n",
        "gb_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# -----------------------------\n",
        "# Inference with time measurement\n",
        "# -----------------------------\n",
        "start_inf = time.time()\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "end_inf = time.time()\n",
        "inference_time = end_inf - start_inf\n",
        "\n",
        "# -----------------------------\n",
        "# Energy measurement\n",
        "# -----------------------------\n",
        "emissions_kg = tracker.stop()\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation Metrics\n",
        "# -----------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred_gb) * 100\n",
        "macro_precision = precision_score(y_test, y_pred_gb, average=\"macro\") * 100\n",
        "macro_recall = recall_score(y_test, y_pred_gb, average=\"macro\") * 100\n",
        "macro_f1 = f1_score(y_test, y_pred_gb, average=\"macro\") * 100\n",
        "class_labels = np.unique(y)\n",
        "\n",
        "# -----------------------------\n",
        "# Print Results\n",
        "# -----------------------------\n",
        "print(\"========= Optimized Gradient Boosting =========\\n\")\n",
        "print(\"--------- Dataset Info ---------\")\n",
        "print(\"Total samples:\", len(X))\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Class labels:\", class_labels)\n",
        "\n",
        "print(\"\\n--------- Model Configuration ---------\")\n",
        "print(\"Number of trees (n_estimators):\", 200)\n",
        "print(\"Learning rate:\", 0.05)\n",
        "print(\"Max depth:\", 5)\n",
        "print(\"Min samples per leaf:\", 5)\n",
        "print(\"Subsample:\", 0.8)\n",
        "\n",
        "print(\"\\n--------- Training Info ---------\")\n",
        "print(\"Training time (seconds):\", round(training_time, 4))\n",
        "print(\"Training CO2 emissions (kg):\", round(emissions_kg, 8))\n",
        "\n",
        "print(\"\\n--------- Inference Info ---------\")\n",
        "print(\"Inference time (seconds):\", round(inference_time, 6))\n",
        "print(\"Inference CO2 emissions (kg):\", 0.0)  # negligible\n",
        "\n",
        "print(\"\\n--------- Performance Metrics ---------\")\n",
        "print(\"Accuracy (%):\", round(accuracy, 2))\n",
        "print(\"Macro Precision (%):\", round(macro_precision, 2))\n",
        "print(\"Macro Recall (%):\", round(macro_recall, 2))\n",
        "print(\"Macro F1-score (%):\", round(macro_f1, 2))\n",
        "\n",
        "print(\"\\n--------- Detailed Classification Report ---------\")\n",
        "print(classification_report(y_test, y_pred_gb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7exDpnmwE4k",
        "outputId": "d563a25d-45da-43af-dabc-f5d1adc36589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 10:18:46] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 10:18:46] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:18:46] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:18:46] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 10:18:46] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 10:18:46] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 10:18:46] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 10:18:46] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:18:46] No GPU found.\n",
            "[codecarbon INFO @ 10:18:46] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 10:18:46] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:18:46]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 10:18:46]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 10:18:46]   CodeCarbon version: 3.2.1\n",
            "[codecarbon INFO @ 10:18:46]   Available RAM : 12.671 GB\n",
            "[codecarbon INFO @ 10:18:46]   CPU count: 2 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 10:18:46]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 10:18:46]   GPU count: None\n",
            "[codecarbon INFO @ 10:18:46]   GPU model: None\n",
            "[codecarbon INFO @ 10:18:46] Emissions data (if any) will be saved to file /content/emissions.csv\n",
            "[codecarbon INFO @ 10:19:01] Energy consumed for RAM : 0.000042 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:19:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:19:01] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 10:19:01] 0.000219 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:19:16] Energy consumed for RAM : 0.000083 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:19:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:19:16] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 10:19:16] 0.000437 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:19:31] Energy consumed for RAM : 0.000125 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:19:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:19:31] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 10:19:31] 0.000656 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:19:46] Energy consumed for RAM : 0.000167 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:19:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:19:46] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 10:19:46] 0.000875 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:20:01] Energy consumed for RAM : 0.000208 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:20:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:20:01] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 10:20:01] 0.001094 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:20:16] Energy consumed for RAM : 0.000250 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:20:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:20:16] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 10:20:16] 0.001312 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:20:31] Energy consumed for RAM : 0.000292 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:20:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:20:31] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 10:20:31] 0.001531 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:20:46] Energy consumed for RAM : 0.000333 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:20:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:20:46] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 10:20:46] 0.001750 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:20:46] 0.003901 g.CO2eq/s mean an estimation of 123.03129927231932 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:21:01] Energy consumed for RAM : 0.000375 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:21:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:21:01] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 10:21:01] 0.001968 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:21:16] Energy consumed for RAM : 0.000417 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:21:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:21:16] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 10:21:16] 0.002187 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:21:31] Energy consumed for RAM : 0.000458 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:21:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:21:31] Energy consumed for All CPU : 0.001948 kWh\n",
            "[codecarbon INFO @ 10:21:31] 0.002406 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:21:46] Energy consumed for RAM : 0.000500 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:21:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:21:46] Energy consumed for All CPU : 0.002125 kWh\n",
            "[codecarbon INFO @ 10:21:46] 0.002624 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:22:01] Energy consumed for RAM : 0.000541 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:22:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:22:01] Energy consumed for All CPU : 0.002302 kWh\n",
            "[codecarbon INFO @ 10:22:01] 0.002843 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:22:16] Energy consumed for RAM : 0.000583 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:22:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:22:16] Energy consumed for All CPU : 0.002479 kWh\n",
            "[codecarbon INFO @ 10:22:16] 0.003062 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:22:31] Energy consumed for RAM : 0.000625 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:22:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:22:31] Energy consumed for All CPU : 0.002656 kWh\n",
            "[codecarbon INFO @ 10:22:31] 0.003280 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:22:46] Energy consumed for RAM : 0.000666 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:22:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:22:46] Energy consumed for All CPU : 0.002833 kWh\n",
            "[codecarbon INFO @ 10:22:46] 0.003499 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:22:46] 0.003901 g.CO2eq/s mean an estimation of 123.03620607311639 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:23:01] Energy consumed for RAM : 0.000708 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:23:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:23:01] Energy consumed for All CPU : 0.003010 kWh\n",
            "[codecarbon INFO @ 10:23:01] 0.003718 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:23:16] Energy consumed for RAM : 0.000750 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:23:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:23:16] Energy consumed for All CPU : 0.003187 kWh\n",
            "[codecarbon INFO @ 10:23:16] 0.003936 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:23:31] Energy consumed for RAM : 0.000791 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:23:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:23:31] Energy consumed for All CPU : 0.003364 kWh\n",
            "[codecarbon INFO @ 10:23:31] 0.004155 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:23:46] Energy consumed for RAM : 0.000833 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:23:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:23:46] Energy consumed for All CPU : 0.003541 kWh\n",
            "[codecarbon INFO @ 10:23:46] 0.004374 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:24:01] Energy consumed for RAM : 0.000875 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:24:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:24:01] Energy consumed for All CPU : 0.003718 kWh\n",
            "[codecarbon INFO @ 10:24:01] 0.004592 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:24:16] Energy consumed for RAM : 0.000916 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:24:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:24:16] Energy consumed for All CPU : 0.003895 kWh\n",
            "[codecarbon INFO @ 10:24:16] 0.004811 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:24:31] Energy consumed for RAM : 0.000958 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:24:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:24:31] Energy consumed for All CPU : 0.004072 kWh\n",
            "[codecarbon INFO @ 10:24:31] 0.005030 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:24:46] Energy consumed for RAM : 0.001000 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:24:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:24:46] Energy consumed for All CPU : 0.004249 kWh\n",
            "[codecarbon INFO @ 10:24:46] 0.005248 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:24:46] 0.003901 g.CO2eq/s mean an estimation of 123.0205559512229 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:25:01] Energy consumed for RAM : 0.001041 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:25:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:25:01] Energy consumed for All CPU : 0.004426 kWh\n",
            "[codecarbon INFO @ 10:25:01] 0.005467 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:25:16] Energy consumed for RAM : 0.001083 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:25:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:25:16] Energy consumed for All CPU : 0.004603 kWh\n",
            "[codecarbon INFO @ 10:25:16] 0.005686 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:25:31] Energy consumed for RAM : 0.001124 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:25:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:25:31] Energy consumed for All CPU : 0.004780 kWh\n",
            "[codecarbon INFO @ 10:25:31] 0.005904 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:25:46] Energy consumed for RAM : 0.001166 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:25:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:25:46] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 10:25:46] 0.006123 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:26:01] Energy consumed for RAM : 0.001208 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:26:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:26:01] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 10:26:01] 0.006342 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:26:16] Energy consumed for RAM : 0.001249 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:26:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:26:16] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 10:26:16] 0.006560 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:26:31] Energy consumed for RAM : 0.001291 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:26:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:26:31] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 10:26:31] 0.006779 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:26:46] Energy consumed for RAM : 0.001333 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:26:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:26:46] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 10:26:46] 0.006998 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:26:46] 0.003901 g.CO2eq/s mean an estimation of 123.03076201673369 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:27:01] Energy consumed for RAM : 0.001374 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:27:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:27:01] Energy consumed for All CPU : 0.005842 kWh\n",
            "[codecarbon INFO @ 10:27:01] 0.007216 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:27:16] Energy consumed for RAM : 0.001416 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:27:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:27:16] Energy consumed for All CPU : 0.006019 kWh\n",
            "[codecarbon INFO @ 10:27:16] 0.007435 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:27:31] Energy consumed for RAM : 0.001458 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:27:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:27:31] Energy consumed for All CPU : 0.006196 kWh\n",
            "[codecarbon INFO @ 10:27:31] 0.007654 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:27:46] Energy consumed for RAM : 0.001499 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:27:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:27:46] Energy consumed for All CPU : 0.006373 kWh\n",
            "[codecarbon INFO @ 10:27:46] 0.007872 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:28:01] Energy consumed for RAM : 0.001541 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:28:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:28:01] Energy consumed for All CPU : 0.006550 kWh\n",
            "[codecarbon INFO @ 10:28:01] 0.008091 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:28:16] Energy consumed for RAM : 0.001583 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:28:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:28:16] Energy consumed for All CPU : 0.006727 kWh\n",
            "[codecarbon INFO @ 10:28:16] 0.008310 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:28:31] Energy consumed for RAM : 0.001624 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:28:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:28:31] Energy consumed for All CPU : 0.006904 kWh\n",
            "[codecarbon INFO @ 10:28:31] 0.008528 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:28:43] Energy consumed for RAM : 0.001658 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:28:43] Delta energy consumed for CPU with constant : 0.000144 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:28:43] Energy consumed for All CPU : 0.007048 kWh\n",
            "[codecarbon INFO @ 10:28:43] 0.008706 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 10:28:43] 0.003901 g.CO2eq/s mean an estimation of 123.03137096678716 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Optimized Gradient Boosting =========\n",
            "\n",
            "--------- Dataset Info ---------\n",
            "Total samples: 115568\n",
            "Training samples: 92454\n",
            "Testing samples: 23114\n",
            "Class labels: [1 2 3 4 5 6]\n",
            "\n",
            "--------- Model Configuration ---------\n",
            "Number of trees (n_estimators): 200\n",
            "Learning rate: 0.05\n",
            "Max depth: 5\n",
            "Min samples per leaf: 5\n",
            "Subsample: 0.8\n",
            "\n",
            "--------- Training Info ---------\n",
            "Training time (seconds): 596.3475\n",
            "Training CO2 emissions (kg): 0.0023299\n",
            "\n",
            "--------- Inference Info ---------\n",
            "Inference time (seconds): 0.860206\n",
            "Inference CO2 emissions (kg): 0.0\n",
            "\n",
            "--------- Performance Metrics ---------\n",
            "Accuracy (%): 88.54\n",
            "Macro Precision (%): 80.06\n",
            "Macro Recall (%): 75.39\n",
            "Macro F1-score (%): 76.53\n",
            "\n",
            "--------- Detailed Classification Report ---------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.85      0.90     12169\n",
            "           2       0.77      0.95      0.85      7327\n",
            "           3       1.00      0.89      0.94      1921\n",
            "           4       0.89      0.97      0.93      1392\n",
            "           5       0.53      0.25      0.34       219\n",
            "           6       0.65      0.62      0.63        86\n",
            "\n",
            "    accuracy                           0.89     23114\n",
            "   macro avg       0.80      0.75      0.77     23114\n",
            "weighted avg       0.90      0.89      0.89     23114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN"
      ],
      "metadata": {
        "id": "sLitNPmvz-kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = [\n",
        "    'location_name', 'last_updated',\n",
        "    'sunrise', 'sunset', 'moonrise', 'moonset'\n",
        "]\n",
        "\n",
        "df = df.drop(columns=drop_cols, errors='ignore')"
      ],
      "metadata": {
        "id": "ppUI5RXJ00mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AQI_category'] = df['air_quality_us-epa-index'].astype(int)"
      ],
      "metadata": {
        "id": "YqlQfc_Z03id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(\n",
        "    df,\n",
        "    columns=df.select_dtypes(include='object').columns,\n",
        "    drop_first=True\n",
        ")"
      ],
      "metadata": {
        "id": "TmMG5TT105jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset preparation\n",
        "# -----------------------------\n",
        "X = df_encoded.drop('AQI_category', axis=1)\n",
        "y = df_encoded['AQI_category'] - 1   # classes 0–5\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# -----------------------------\n",
        "# Train-test split (same as RF)\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# One-hot encoding\n",
        "y_train_cat = to_categorical(y_train, num_classes=6)\n",
        "y_test_cat = to_categorical(y_test, num_classes=6)\n",
        "\n",
        "# -----------------------------\n",
        "# DNN model\n",
        "# -----------------------------\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Early stopping\n",
        "# -----------------------------\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Training with time measurement\n",
        "# -----------------------------\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train_cat,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=256,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# -----------------------------\n",
        "# Predictions\n",
        "# -----------------------------\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred_dnn = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation Metrics (same as RF)\n",
        "# -----------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred_dnn) * 100\n",
        "macro_precision = precision_score(y_test, y_pred_dnn, average=\"macro\") * 100\n",
        "macro_recall = recall_score(y_test, y_pred_dnn, average=\"macro\") * 100\n",
        "macro_f1 = f1_score(y_test, y_pred_dnn, average=\"macro\") * 100\n",
        "class_labels = np.unique(y)\n",
        "\n",
        "# -----------------------------\n",
        "# Print Results\n",
        "# -----------------------------\n",
        "print(\"--------- Dataset Info ---------\")\n",
        "print(\"Total samples:\", len(X))\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Class labels:\", class_labels)\n",
        "\n",
        "print(\"\\n--------- Training Info ---------\")\n",
        "print(\"Training time (seconds):\", round(training_time, 4))\n",
        "print(\"Optimizer: Adam\")\n",
        "print(\"Batch size:\", 256)\n",
        "print(\"Learning rate: Adaptive (Adam)\")\n",
        "print(\"Epochs trained:\", len(history.history['loss']))\n",
        "\n",
        "print(\"\\n--------- Performance Metrics ---------\")\n",
        "print(\"Accuracy (%):\", round(accuracy, 2))\n",
        "print(\"Macro Precision (%):\", round(macro_precision, 2))\n",
        "print(\"Macro Recall (%):\", round(macro_recall, 2))\n",
        "print(\"Macro F1-score (%):\", round(macro_f1, 2))\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "tracker_dnn = EmissionsTracker(project_name=\"DNN_AQI\")\n",
        "\n",
        "start_time = time.time()\n",
        "tracker_dnn.start()\n",
        "\n",
        "# Train DNN\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train_cat,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=256,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "emissions_dnn = tracker_dnn.stop()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"DNN Training Time (s):\", round(end_time - start_time, 4))\n",
        "print(\"DNN CO2 Emissions (kg):\", emissions_dnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfrgkOj10nvV",
        "outputId": "3fb61a79-9bdc-4014-f559-119a2d426bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6635 - loss: 0.8387 - val_accuracy: 0.9759 - val_loss: 0.0940\n",
            "Epoch 2/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9522 - loss: 0.1422 - val_accuracy: 0.9918 - val_loss: 0.0427\n",
            "Epoch 3/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9795 - loss: 0.0620 - val_accuracy: 0.9953 - val_loss: 0.0222\n",
            "Epoch 4/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0444 - val_accuracy: 0.9971 - val_loss: 0.0221\n",
            "Epoch 5/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0312 - val_accuracy: 0.9968 - val_loss: 0.0172\n",
            "Epoch 6/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0249 - val_accuracy: 0.9977 - val_loss: 0.0168\n",
            "Epoch 7/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0206 - val_accuracy: 0.9970 - val_loss: 0.0143\n",
            "Epoch 8/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0189 - val_accuracy: 0.9979 - val_loss: 0.0230\n",
            "Epoch 9/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 0.9985 - val_loss: 0.0240\n",
            "Epoch 10/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9956 - loss: 0.0134 - val_accuracy: 0.9978 - val_loss: 0.0232\n",
            "Epoch 11/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9978 - val_loss: 0.0207\n",
            "Epoch 12/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0141 - val_accuracy: 0.9985 - val_loss: 0.0189\n",
            "Epoch 13/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9960 - loss: 0.0119 - val_accuracy: 0.9986 - val_loss: 0.0228\n",
            "Epoch 14/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0078 - val_accuracy: 0.9971 - val_loss: 0.0298\n",
            "Epoch 15/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0115 - val_accuracy: 0.9983 - val_loss: 0.0181\n",
            "Epoch 16/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9986 - val_loss: 0.0237\n",
            "Epoch 17/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0097 - val_accuracy: 0.9989 - val_loss: 0.0154\n",
            "Epoch 18/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0082 - val_accuracy: 0.9989 - val_loss: 0.0205\n",
            "Epoch 19/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.9988 - val_loss: 0.0238\n",
            "Epoch 20/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.9985 - val_loss: 0.0192\n",
            "Epoch 21/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9986 - val_loss: 0.0195\n",
            "Epoch 22/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9991 - val_loss: 0.0172\n",
            "Epoch 23/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.9992 - val_loss: 0.0187\n",
            "Epoch 24/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9989 - val_loss: 0.0203\n",
            "Epoch 25/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.9994 - val_loss: 0.0177\n",
            "Epoch 26/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9995 - val_loss: 0.0198\n",
            "Epoch 27/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9994 - val_loss: 0.0200\n",
            "Epoch 28/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9995 - val_loss: 0.0201\n",
            "Epoch 29/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9992 - val_loss: 0.0229\n",
            "Epoch 30/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.9992 - val_loss: 0.0222\n",
            "Epoch 31/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9989 - val_loss: 0.0231\n",
            "Epoch 32/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9990 - val_loss: 0.0227\n",
            "Epoch 33/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 0.9987 - val_loss: 0.0285\n",
            "Epoch 34/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9993 - val_loss: 0.0203\n",
            "Epoch 35/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9994 - val_loss: 0.0265\n",
            "Epoch 36/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.9994 - val_loss: 0.0285\n",
            "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 10:38:04] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 10:38:04] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:38:04] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:38:04] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 10:38:04] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 10:38:04] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 10:38:04] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 10:38:04] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:38:04] No GPU found.\n",
            "[codecarbon INFO @ 10:38:04] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 10:38:04] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:38:04]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 10:38:04]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 10:38:04]   CodeCarbon version: 3.2.1\n",
            "[codecarbon INFO @ 10:38:04]   Available RAM : 12.671 GB\n",
            "[codecarbon INFO @ 10:38:04]   CPU count: 2 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 10:38:04]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 10:38:04]   GPU count: None\n",
            "[codecarbon INFO @ 10:38:04]   GPU model: None\n",
            "[codecarbon INFO @ 10:38:05] Emissions data (if any) will be saved to file /content/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Dataset Info ---------\n",
            "Total samples: 115568\n",
            "Training samples: 92454\n",
            "Testing samples: 23114\n",
            "Class labels: [0 1 2 3 4 5]\n",
            "\n",
            "--------- Training Info ---------\n",
            "Training time (seconds): 95.3413\n",
            "Optimizer: Adam\n",
            "Batch size: 256\n",
            "Learning rate: Adaptive (Adam)\n",
            "Epochs trained: 36\n",
            "\n",
            "--------- Performance Metrics ---------\n",
            "Accuracy (%): 99.96\n",
            "Macro Precision (%): 99.16\n",
            "Macro Recall (%): 99.66\n",
            "Macro F1-score (%): 99.4\n",
            "Epoch 1/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9988 - val_loss: 0.0251\n",
            "Epoch 2/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9988 - val_loss: 0.0217\n",
            "Epoch 3/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.9992 - val_loss: 0.0208\n",
            "Epoch 4/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 0.9994 - val_loss: 0.0181\n",
            "Epoch 5/100\n",
            "\u001b[1m 42/289\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9974 - loss: 0.0071"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:38:20] Energy consumed for RAM : 0.000042 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:38:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:38:20] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 10:38:20] 0.000219 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9992 - val_loss: 0.0188\n",
            "Epoch 6/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9993 - val_loss: 0.0225\n",
            "Epoch 7/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9994 - val_loss: 0.0261\n",
            "Epoch 8/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9983 - val_loss: 0.0364\n",
            "Epoch 9/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9994 - val_loss: 0.0255\n",
            "Epoch 10/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.9995 - val_loss: 0.0268\n",
            "Epoch 11/100\n",
            "\u001b[1m  1/289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.6879e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:38:35] Energy consumed for RAM : 0.000083 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:38:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:38:35] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 10:38:35] 0.000437 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9993 - val_loss: 0.0375\n",
            "Epoch 12/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9994 - val_loss: 0.0298\n",
            "Epoch 13/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0061 - val_accuracy: 0.9996 - val_loss: 0.0253\n",
            "Epoch 14/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9992 - val_loss: 0.0308\n",
            "Epoch 15/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9995 - val_loss: 0.0295\n",
            "Epoch 16/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:38:50] Energy consumed for RAM : 0.000125 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:38:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:38:50] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 10:38:50] 0.000656 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 0.9994 - val_loss: 0.0318\n",
            "Epoch 17/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0053 - val_accuracy: 0.9996 - val_loss: 0.0304\n",
            "Epoch 18/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9993 - val_loss: 0.0286\n",
            "Epoch 19/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9994 - val_loss: 0.0284\n",
            "Epoch 20/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9995 - val_loss: 0.0248\n",
            "Epoch 21/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0046 - val_accuracy: 0.9997 - val_loss: 0.0284\n",
            "Epoch 22/100\n",
            "\u001b[1m 17/289\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:39:05] Energy consumed for RAM : 0.000167 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:39:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:39:05] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 10:39:05] 0.000875 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9996 - val_loss: 0.0302\n",
            "Epoch 23/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9992 - val_loss: 0.0310\n",
            "Epoch 24/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9997 - val_loss: 0.0276\n",
            "Epoch 25/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9997 - val_loss: 0.0241\n",
            "Epoch 26/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0021"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:39:20] Energy consumed for RAM : 0.000208 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:39:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:39:20] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 10:39:20] 0.001093 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9997 - val_loss: 0.0225\n",
            "Epoch 27/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9994 - val_loss: 0.0278\n",
            "Epoch 28/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9995 - val_loss: 0.0279\n",
            "Epoch 29/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9996 - val_loss: 0.0312\n",
            "Epoch 30/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9996 - val_loss: 0.0306\n",
            "Epoch 31/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.9994 - val_loss: 0.0432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:39:34] Energy consumed for RAM : 0.000249 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 10:39:34] Delta energy consumed for CPU with constant : 0.000171 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:39:34] Energy consumed for All CPU : 0.001057 kWh\n",
            "[codecarbon INFO @ 10:39:34] 0.001305 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon WARNING @ 10:39:34] The CSV format has changed, backing up old emission file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN Training Time (s): 89.5617\n",
            "DNN CO2 Emissions (kg): 0.0003492941761441426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimized DNN"
      ],
      "metadata": {
        "id": "ahuGa4cM2K-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming df_encoded is already your cleaned dataset\n",
        "X = df_encoded.drop('AQI_category', axis=1)\n",
        "y = df_encoded['AQI_category'] - 1  # classes 0–5\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# One-hot encoding\n",
        "num_classes = 6\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "LFsdwT-Q3KXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "teacher_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train teacher\n",
        "start_time = time.time()\n",
        "teacher_history = teacher_model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=256,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\" Teacher trained in {round(end_time - start_time, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvSC28F83PdO",
        "outputId": "ca2e282f-52c6-4027-a6ae-b1d250317f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.6157 - loss: 0.9361 - val_accuracy: 0.9719 - val_loss: 0.1243\n",
            "Epoch 2/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9415 - loss: 0.1687 - val_accuracy: 0.9930 - val_loss: 0.0374\n",
            "Epoch 3/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9768 - loss: 0.0678 - val_accuracy: 0.9949 - val_loss: 0.0270\n",
            "Epoch 4/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9842 - loss: 0.0464 - val_accuracy: 0.9963 - val_loss: 0.0255\n",
            "Epoch 5/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0330 - val_accuracy: 0.9971 - val_loss: 0.0211\n",
            "Epoch 6/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0267 - val_accuracy: 0.9965 - val_loss: 0.0205\n",
            "Epoch 7/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0243 - val_accuracy: 0.9977 - val_loss: 0.0185\n",
            "Epoch 8/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0194 - val_accuracy: 0.9975 - val_loss: 0.0210\n",
            "Epoch 9/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0157 - val_accuracy: 0.9984 - val_loss: 0.0179\n",
            "Epoch 10/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 0.0145 - val_accuracy: 0.9985 - val_loss: 0.0167\n",
            "Epoch 11/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0105 - val_accuracy: 0.9988 - val_loss: 0.0221\n",
            "Epoch 12/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0120 - val_accuracy: 0.9979 - val_loss: 0.0329\n",
            "Epoch 13/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9956 - loss: 0.0133 - val_accuracy: 0.9988 - val_loss: 0.0358\n",
            "Epoch 14/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0107 - val_accuracy: 0.9989 - val_loss: 0.0148\n",
            "Epoch 15/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.0096 - val_accuracy: 0.9989 - val_loss: 0.0178\n",
            "Epoch 16/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0085 - val_accuracy: 0.9989 - val_loss: 0.0181\n",
            "Epoch 17/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 0.9989 - val_loss: 0.0231\n",
            "Epoch 18/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9989 - val_loss: 0.0316\n",
            "Epoch 19/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.9981 - val_loss: 0.0326\n",
            "Epoch 20/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.0083 - val_accuracy: 0.9992 - val_loss: 0.0324\n",
            "Epoch 21/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0084 - val_accuracy: 0.9990 - val_loss: 0.0258\n",
            "Epoch 22/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0087 - val_accuracy: 0.9992 - val_loss: 0.0298\n",
            "Epoch 23/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9991 - val_loss: 0.0314\n",
            "Epoch 24/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 0.9989 - val_loss: 0.0401\n",
            "Epoch 25/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9981 - val_loss: 0.0473\n",
            "Epoch 26/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9986 - val_loss: 0.0291\n",
            "Epoch 27/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9990 - val_loss: 0.0376\n",
            "Epoch 28/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 0.9991 - val_loss: 0.0305\n",
            "Epoch 29/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9991 - val_loss: 0.0341\n",
            "Epoch 30/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.9989 - val_loss: 0.0389\n",
            "✅ Teacher trained in 100.27 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "student_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "B0gFjpxW3tXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Soft targets from teacher\n",
        "teacher_logits = teacher_model.predict(X_train)\n",
        "temperature = 5.0\n",
        "\n",
        "def distillation_loss(y_true, y_pred):\n",
        "    y_true_soft = tf.nn.softmax(y_true / temperature)\n",
        "    y_pred_soft = tf.nn.softmax(y_pred / temperature)\n",
        "    return tf.keras.losses.KLDivergence()(y_true_soft, y_pred_soft)\n",
        "\n",
        "# Compile student with distillation loss\n",
        "student_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=distillation_loss,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train student\n",
        "student_history = student_model.fit(\n",
        "    X_train, teacher_logits,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=256,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bH4KmLo3w-u",
        "outputId": "ee55396d-7baf-468b-8945-de88d75af4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2890/2890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6364 - loss: 0.0017 - val_accuracy: 0.9802 - val_loss: 1.8378e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 1.4315e-04 - val_accuracy: 0.9850 - val_loss: 1.1075e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 1.0360e-04 - val_accuracy: 0.9847 - val_loss: 1.0354e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 1.0500e-04 - val_accuracy: 0.9851 - val_loss: 9.7489e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 9.2858e-05 - val_accuracy: 0.9853 - val_loss: 9.1867e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 8.5546e-05 - val_accuracy: 0.9857 - val_loss: 8.9564e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 8.1382e-05 - val_accuracy: 0.9857 - val_loss: 8.7201e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 8.2532e-05 - val_accuracy: 0.9857 - val_loss: 8.4483e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 7.8242e-05 - val_accuracy: 0.9854 - val_loss: 8.2304e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 8.0925e-05 - val_accuracy: 0.9848 - val_loss: 8.3929e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 7.9859e-05 - val_accuracy: 0.9850 - val_loss: 8.2045e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 7.5074e-05 - val_accuracy: 0.9849 - val_loss: 8.1426e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 7.7530e-05 - val_accuracy: 0.9854 - val_loss: 7.7242e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9864 - loss: 7.2593e-05 - val_accuracy: 0.9855 - val_loss: 7.6190e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 7.6253e-05 - val_accuracy: 0.9852 - val_loss: 7.8514e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 7.7031e-05 - val_accuracy: 0.9850 - val_loss: 7.9618e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 7.3405e-05 - val_accuracy: 0.9854 - val_loss: 7.6426e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 7.4463e-05 - val_accuracy: 0.9853 - val_loss: 7.5794e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 7.2170e-05 - val_accuracy: 0.9858 - val_loss: 7.3031e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 7.5539e-05 - val_accuracy: 0.9855 - val_loss: 7.5657e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 7.1144e-05 - val_accuracy: 0.9853 - val_loss: 7.5350e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 7.2679e-05 - val_accuracy: 0.9849 - val_loss: 7.9911e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9848 - loss: 8.0811e-05 - val_accuracy: 0.9857 - val_loss: 7.4321e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9858 - loss: 7.4115e-05 - val_accuracy: 0.9855 - val_loss: 7.5236e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 7.1268e-05 - val_accuracy: 0.9851 - val_loss: 7.7838e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 7.5732e-05 - val_accuracy: 0.9856 - val_loss: 7.4223e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 7.2921e-05 - val_accuracy: 0.9855 - val_loss: 7.4511e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9858 - loss: 7.4485e-05 - val_accuracy: 0.9859 - val_loss: 7.1964e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 7.3049e-05 - val_accuracy: 0.9857 - val_loss: 7.3456e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 7.1620e-05 - val_accuracy: 0.9858 - val_loss: 7.4066e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 6.7578e-05 - val_accuracy: 0.9859 - val_loss: 7.1870e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 6.9615e-05 - val_accuracy: 0.9857 - val_loss: 7.2860e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 7.5123e-05 - val_accuracy: 0.9859 - val_loss: 7.1399e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 6.8390e-05 - val_accuracy: 0.9860 - val_loss: 7.0925e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9864 - loss: 7.0005e-05 - val_accuracy: 0.9860 - val_loss: 7.1017e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9858 - loss: 7.2941e-05 - val_accuracy: 0.9859 - val_loss: 7.0776e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9864 - loss: 6.9740e-05 - val_accuracy: 0.9859 - val_loss: 7.1657e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9869 - loss: 6.7012e-05 - val_accuracy: 0.9859 - val_loss: 7.1441e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9866 - loss: 6.8803e-05 - val_accuracy: 0.9856 - val_loss: 7.3502e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 6.9495e-05 - val_accuracy: 0.9859 - val_loss: 7.1429e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 6.8269e-05 - val_accuracy: 0.9859 - val_loss: 7.1139e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 6.7689e-05 - val_accuracy: 0.9859 - val_loss: 7.1478e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 7.2306e-05 - val_accuracy: 0.9852 - val_loss: 7.4983e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 7.2770e-05 - val_accuracy: 0.9860 - val_loss: 7.1110e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 6.7062e-05 - val_accuracy: 0.9860 - val_loss: 7.0953e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 6.9580e-05 - val_accuracy: 0.9860 - val_loss: 7.0845e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 6.8114e-05 - val_accuracy: 0.9859 - val_loss: 7.1387e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 6.7423e-05 - val_accuracy: 0.9860 - val_loss: 7.1723e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 7.2389e-05 - val_accuracy: 0.9860 - val_loss: 7.0697e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9869 - loss: 6.6998e-05 - val_accuracy: 0.9862 - val_loss: 7.0156e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = student_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "precision = precision_score(y_test, y_pred, average='macro') * 100\n",
        "recall = recall_score(y_test, y_pred, average='macro') * 100\n",
        "f1 = f1_score(y_test, y_pred, average='macro') * 100\n",
        "\n",
        "print(\"--------- Student DNN Performance ---------\")\n",
        "print(f\"Accuracy: {round(accuracy,2)}%\")\n",
        "print(f\"Macro Precision: {round(precision,2)}%\")\n",
        "print(f\"Macro Recall: {round(recall,2)}%\")\n",
        "print(f\"Macro F1: {round(f1,2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKHwjhzi4TkW",
        "outputId": "9bb35c57-4184-47c3-e2e1-2bc9679f03fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "--------- Student DNN Performance ---------\n",
            "Accuracy: 98.61%\n",
            "Macro Precision: 63.88%\n",
            "Macro Recall: 66.58%\n",
            "Macro F1: 65.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to TFLite with dynamic range quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(student_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"student_model_quantized.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\" Student model quantized and saved as 'student_model_quantized.tflite'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJYNjupo4XTG",
        "outputId": "0d11a771-0c40-4a4c-fd00-5f19119f5670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmp1nvc26uj'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 505), dtype=tf.float32, name='keras_tensor_26')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136329204121680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136329204123984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136329204135312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136329204132624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136329204133776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136329204134352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            " Student model quantized and saved as 'student_model_quantized.tflite'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import time\n",
        "\n",
        "# -----------------------------\n",
        "# Load TFLite model\n",
        "# -----------------------------\n",
        "interpreter = tf.lite.Interpreter(model_path=\"student_model_quantized.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# -----------------------------\n",
        "# Run inference and measure time\n",
        "# -----------------------------\n",
        "start_time = time.time()\n",
        "\n",
        "# Prepare full test set as float32\n",
        "X_test_float = X_test.astype(np.float32)\n",
        "y_pred_tflite = []\n",
        "\n",
        "for i in range(len(X_test_float)):\n",
        "    interpreter.set_tensor(input_details[0]['index'], X_test_float[i:i+1])\n",
        "    interpreter.invoke()\n",
        "    pred = interpreter.get_tensor(output_details[0]['index'])\n",
        "    y_pred_tflite.append(np.argmax(pred, axis=1)[0])\n",
        "\n",
        "end_time = time.time()\n",
        "inference_time = end_time - start_time\n",
        "\n",
        "# -----------------------------\n",
        "# Compute metrics\n",
        "# -----------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred_tflite) * 100\n",
        "macro_precision = precision_score(y_test, y_pred_tflite, average='macro') * 100\n",
        "macro_recall = recall_score(y_test, y_pred_tflite, average='macro') * 100\n",
        "macro_f1 = f1_score(y_test, y_pred_tflite, average='macro') * 100\n",
        "\n",
        "# -----------------------------\n",
        "# Estimate CO2 emission (approximate)\n",
        "# -----------------------------\n",
        "# Assume 0.00005 kg CO2 per second of inference (typical for small CPU model)\n",
        "co2_emission = inference_time * 0.00005  # kg CO2\n",
        "\n",
        "# -----------------------------\n",
        "# Print Results\n",
        "# -----------------------------\n",
        "print(\"------ Final Student Model Metrics (Quantized) ------\")\n",
        "print(f\"Accuracy (%):       {accuracy:.2f}\")\n",
        "print(f\"Macro Precision (%): {macro_precision:.2f}\")\n",
        "print(f\"Macro Recall (%):    {macro_recall:.2f}\")\n",
        "print(f\"Macro F1-score (%):  {macro_f1:.2f}\")\n",
        "print(f\"Inference time (s):  {inference_time:.4f}\")\n",
        "print(f\"Estimated CO2 (kg): {co2_emission:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPI7u78X4b7u",
        "outputId": "57f162e0-f41f-49a9-92aa-1b7423c3e395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ Final Student Model Metrics (Quantized) ------\n",
            "Accuracy (%):       98.59\n",
            "Macro Precision (%): 63.84\n",
            "Macro Recall (%):    66.56\n",
            "Macro F1-score (%):  65.14\n",
            "Inference time (s):  0.3839\n",
            "Estimated CO2 (kg): 0.000019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "DonVmtDM4glG",
        "outputId": "19a01bf8-59dd-4b69-9266-edb083cafa67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m103,988\u001b[0m (406.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,988</span> (406.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,662\u001b[0m (135.40 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,662</span> (135.40 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m69,326\u001b[0m (270.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,326</span> (270.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Assuming y_train contains integer class labels (0 to 5)\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "print(\"Class weights:\", class_weights_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUKyBr9h4jyP",
        "outputId": "b9f62cda-de1e-43e6-dc8c-a0cf3d4d5ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(0.31658208863230125), 1: np.float64(0.5257608844001638), 2: np.float64(2.0058578495183546), 3: np.float64(2.7674209770114944), 4: np.float64(17.53014789533561), 5: np.float64(44.79360465116279)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Temperature for distillation\n",
        "temperature = 5.0\n",
        "alpha = 0.5  # balance between teacher loss and student loss\n",
        "\n",
        "# Custom distillation loss\n",
        "def distillation_loss(y_true, y_pred, teacher_preds):\n",
        "    # Categorical crossentropy with hard labels\n",
        "    hard_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "    # KL divergence with soft labels\n",
        "    soft_loss = tf.keras.losses.KLDivergence()(\n",
        "        tf.nn.softmax(teacher_preds / temperature),\n",
        "        tf.nn.softmax(y_pred / temperature)\n",
        "    )\n",
        "    return alpha * hard_loss + (1 - alpha) * soft_loss"
      ],
      "metadata": {
        "id": "PA8zPY6C4lx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # use distillation_loss if teacher available\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = student_model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_split=0.2,\n",
        "    epochs=20,\n",
        "    batch_size=256,\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83u8KWkI4oAG",
        "outputId": "f7ef8629-0715-4fcf-812f-31c765d1793d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 5.9350 - val_accuracy: 0.9982 - val_loss: 0.0145\n",
            "Epoch 2/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0707 - val_accuracy: 0.9990 - val_loss: 0.0085\n",
            "Epoch 3/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0340 - val_accuracy: 0.9991 - val_loss: 0.0082\n",
            "Epoch 4/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0121 - val_accuracy: 0.9991 - val_loss: 0.0101\n",
            "Epoch 5/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0070 - val_accuracy: 0.9992 - val_loss: 0.0084\n",
            "Epoch 6/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9992 - val_loss: 0.0094\n",
            "Epoch 7/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9994 - val_loss: 0.0099\n",
            "Epoch 8/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9993 - val_loss: 0.0109\n",
            "Epoch 9/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.4205e-04 - val_accuracy: 0.9993 - val_loss: 0.0121\n",
            "Epoch 10/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9993 - val_loss: 0.0130\n",
            "Epoch 11/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.3103e-04 - val_accuracy: 0.9994 - val_loss: 0.0138\n",
            "Epoch 12/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7611e-04 - val_accuracy: 0.9994 - val_loss: 0.0146\n",
            "Epoch 13/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.8765e-04 - val_accuracy: 0.9994 - val_loss: 0.0155\n",
            "Epoch 14/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8757e-04 - val_accuracy: 0.9995 - val_loss: 0.0158\n",
            "Epoch 15/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0031 - val_accuracy: 0.9989 - val_loss: 0.0196\n",
            "Epoch 16/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0575 - val_accuracy: 0.9988 - val_loss: 0.0284\n",
            "Epoch 17/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0041 - val_accuracy: 0.9989 - val_loss: 0.0225\n",
            "Epoch 18/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0041 - val_accuracy: 0.9993 - val_loss: 0.0233\n",
            "Epoch 19/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0181\n",
            "Epoch 20/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0020 - val_accuracy: 0.9993 - val_loss: 0.0163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Predict on test set\n",
        "# -------------------------------\n",
        "start_time = time.time()\n",
        "y_pred_probs = student_model.predict(X_test)\n",
        "inference_time = time.time() - start_time\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Compute metrics\n",
        "# -------------------------------\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "macro_precision = report['macro avg']['precision']\n",
        "macro_recall = report['macro avg']['recall']\n",
        "macro_f1 = report['macro avg']['f1-score']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Estimate CO2 (roughly)\n",
        "# -------------------------------\n",
        "# You can use your previous formula, e.g. CO2 (kg) = inference_time * 0.00005\n",
        "co2_emission = inference_time * 0.00005\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Print results\n",
        "# -------------------------------\n",
        "print(\"Student Model Evaluation:\")\n",
        "print(f\"Accuracy (%):       {accuracy*100:.2f}\")\n",
        "print(f\"Macro Precision (%): {macro_precision*100:.2f}\")\n",
        "print(f\"Macro Recall (%):    {macro_recall*100:.2f}\")\n",
        "print(f\"Macro F1-score (%):  {macro_f1*100:.2f}\")\n",
        "print(f\"Inference time (s):  {inference_time:.4f}\")\n",
        "print(f\"Estimated CO2 (kg):  {co2_emission:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLbBjX8g41su",
        "outputId": "21c20508-b5bc-4083-97c0-bcf4cff6020d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
            "Student Model Evaluation:\n",
            "Accuracy (%):       99.90\n",
            "Macro Precision (%): 98.68\n",
            "Macro Recall (%):    99.54\n",
            "Macro F1-score (%):  99.10\n",
            "Inference time (s):  5.4168\n",
            "Estimated CO2 (kg):  0.000271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison table of all model**"
      ],
      "metadata": {
        "id": "JUeYJVwZBg66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model                      | Accuracy (%) | Macro Precision (%) | Macro Recall (%) | Macro F1 (%) | Training Time (s) | Inference Time (s) | CO₂ Emissions (kg) | Notes                                         |\n",
        "| -------------------------- | ------------ | ------------------- | ---------------- | ------------ | ----------------- | ------------------ | ------------------ | --------------------------------------------- |\n",
        "| **Random Forest (RF)**     | **88.79**    | 78.76               | 71.21            | 73.28        | 15.48             | —                  | 0.000341           | Strong baseline, balanced performance         |\n",
        "| **Optimized RF**           | 86.49        | 73.87               | **77.44**        | **75.23**    | **7.08**          | 0.17               | **0.000001**       | Best RF trade-off (Green AI)                  |\n",
        "| **Decision Tree (DT)**     | 85.65        | 67.37               | **78.41**        | 69.76        | 2.31              | —                  | —                  | Fast but unstable                             |\n",
        "| **Optimized DT**           | 84.11        | 65.40               | 77.83            | 66.86        | **0.74**          | **0.0085**         | 0.000003           | Ultra-low energy, edge-friendly               |\n",
        "| **Gradient Boosting (GB)** | 87.84        | 72.84               | 67.01            | 67.77        | 231.91            | —                  | 0.000888           | High cost, limited gain                       |\n",
        "| **Optimized GB**           | **88.54**    | **80.06**           | 75.39            | **76.53**    | **596.35**        | 0.86               | **0.00233**        | Best GB accuracy, worst efficiency            |\n",
        "| **DNN**                    | 🟢 **99.96** | **99.16**           | **99.66**        | **99.40**    | 95.34             | —                  | 0.000349           | Extremely high accuracy (risk of overfitting) |\n",
        "| **Optimized DNN (ODNN)**   | **99.90**    | 98.68               | 99.54            | 99.10        | —                 | **5.42**           | **0.000271**       | Knowledge distillation, greener DNN           |\n"
      ],
      "metadata": {
        "id": "9a2eCMgUBu0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "data = {\n",
        "    \"Model\": [\"RF\", \"Opt RF\", \"DT\", \"Opt DT\", \"GB\", \"Opt GB\", \"DNN\", \"ODNN\"],\n",
        "    \"Accuracy\": [99.94, 86.49, 85.65, 84.11, 87.84, 88.54, 99.96, 99.90],\n",
        "    \"TrainingTime\": [32.01, 8.53, 2.31, 0.735, 231.91, 596.35, 95.34, 5.42],\n",
        "    \"CO2\": [9.29e-05, 3.31e-05, 1e-06, 3e-06, 8.88e-04, 0.00233, 0.000349, 0.000271]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Scale CO2 for bubble size\n",
        "df['CO2_size'] = df['CO2'] / df['CO2'].max() * 1000 + 50  # scale for visibility\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "scatter = sns.scatterplot(\n",
        "    data=df,\n",
        "    x=\"TrainingTime\",\n",
        "    y=\"Accuracy\",\n",
        "    size=\"CO2_size\",\n",
        "    hue=\"Accuracy\",\n",
        "    palette=\"viridis\",\n",
        "    sizes=(100, 1000),\n",
        "    alpha=0.9,\n",
        "    edgecolor=\"black\"\n",
        ")\n",
        "\n",
        "# Log scales for better visibility\n",
        "plt.xscale('log')\n",
        "plt.yscale('linear')  # Accuracy is already 0-100%\n",
        "\n",
        "# Annotate models\n",
        "for i in range(df.shape[0]):\n",
        "    plt.text(df.TrainingTime[i]*1.05, df.Accuracy[i]+0.2, df.Model[i], fontsize=10, weight='bold')\n",
        "\n",
        "plt.xlabel(\"Training Time (s) [log scale]\", fontsize=12)\n",
        "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
        "plt.title(\"✨ Accuracy vs Training Time vs CO2 Emissions ✨\", fontsize=16, weight='bold')\n",
        "\n",
        "# Legend tweaks\n",
        "handles, labels = scatter.get_legend_handles_labels()\n",
        "plt.legend(handles=handles[1:], labels=labels[1:], title=\"Accuracy & CO2 (size)\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "id": "isfM1m5R9tlv",
        "outputId": "1fd7c250-fcb0-4ff6-ff07-2333bdd4011a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 11:14:46] Energy consumed for RAM : 0.005075 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 11:14:46] Delta energy consumed for CPU with constant : 0.000012 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 11:14:46] Energy consumed for All CPU : 0.021549 kWh\n",
            "[codecarbon INFO @ 11:14:46] 0.026624 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "/tmp/ipython-input-4009231553.py:51: UserWarning: Glyph 10024 (\\N{SPARKLES}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 10024 (\\N{SPARKLES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}